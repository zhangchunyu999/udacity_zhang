{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Advanced Lane Finding Project**\n",
    "\n",
    "# Project Outline\n",
    "\n",
    "### I wrote the code for each step is in the file named 'Project2.ipynb'\n",
    "\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image1-1]: ./output_images/1.png \n",
    "[image1-2]: ./output_images/2.png \n",
    "[image1-3]: ./output_images/3.png \n",
    "[image1-4]: ./output_images/4.png \n",
    "[image1-5]: ./output_images/5.png \n",
    "[image1-6]: ./output_images/6.png \n",
    "[image1-7]: ./output_images/7.png \n",
    "[image1-8]: ./output_images/8.png \n",
    "[image1-9]: ./output_images/9.png \n",
    "[image1-10]: ./output_images/10.png \n",
    "[image1-11]: ./output_images/11.png \n",
    "[image1-12]: ./output_images/12.png \n",
    "[image1-13]: ./output_images/13.png \n",
    "[image1-14]: ./output_images/14.png \n",
    "[image1-15]: ./output_images/15.png \n",
    "[image1-16]: ./output_images/16.png \n",
    "[image1-17]: ./output_images/17.png \n",
    "[image2]: ./output_images/18.png \n",
    "\n",
    "[image3]: ./output_images/19.png \n",
    "[image4]: ./output_images/20.png \n",
    "[image5]: ./output_images/21.png \n",
    "[image6]: ./output_images/22.png \n",
    "[image7]: ./output_images/23.png \n",
    "[image8]: ./output_images/24.png\n",
    "[image9]: ./output_images/25.png \n",
    "[image10]: ./output_images/26.png \n",
    "[image11]: ./output_images/27.png \n",
    "[image12]: ./output_images/28.png\n",
    "[image13]: ./output_images/29.png\n",
    "[image14]: ./output_images/30.png\n",
    "[image15]: ./output_images/31.png\n",
    "[image16]: ./output_images/32.png\n",
    "\n",
    "[image17]: ./challenge_image/frame9.jpg\n",
    "\n",
    "[video1]: ./project_output_video.mp4 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Camera Calibration\n",
    "\n",
    "### 1. Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "\n",
    "* First, readin the images from the folder of calibration images with the function 'glob()' and 'cv2.imread()'.\n",
    "* Second, I,set the numbers of the chessboard as'nx=9,ny=6'\n",
    "* Thirdly, as what I learned in the lesson I used the function 'cv2.findChessboardCorners()' to find the image points (chessboard corners) .\n",
    "* Finally, I used the function 'cv2.drawChessboardCorners()' to draw the lines of each chessboard corner.\n",
    "\n",
    "\n",
    "![alt text][image1-1]\n",
    "![alt text][image1-2]\n",
    "![alt text][image1-3]\n",
    "![alt text][image1-4]\n",
    "![alt text][image1-5]\n",
    "![alt text][image1-6]\n",
    "![alt text][image1-7]\n",
    "![alt text][image1-8]\n",
    "![alt text][image1-9]\n",
    "![alt text][image1-10]\n",
    "![alt text][image1-11]\n",
    "![alt text][image1-12]\n",
    "![alt text][image1-13]\n",
    "![alt text][image1-14]\n",
    "![alt text][image1-15]\n",
    "![alt text][image1-16]\n",
    "![alt text][image1-17]\n",
    "\n",
    "### 2.Apply a distortion correction to raw images.\n",
    "\n",
    "* In this step for calibrating the images, I used the function 'cv2.calibrateCamera()' to take out the parameter of mtx and dist, and save them in a pickle file.\n",
    "* Then, I used the function 'cv2.undistort()' to output the undistorted and warped image as the following data.\n",
    "\n",
    "![alt text][image2]\n",
    "\n",
    "## Pipeline (single images)\n",
    "\n",
    "### 1. Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "\n",
    "I used a combination of color and gradient thresholds to generate a binary image. Here's an example of my output for this step. \n",
    "\n",
    "* For checking the different results of each function I have output the 'thresholded S', 'thresholded R', 'thresholded G', 'thresholded B', 'thresholded Sobelx', 'thresholded Sobely'\n",
    "* In the end I used a  combination of color and gradient as '(binary_s_output == 1) &(binary_l_output==1)| (binary_sobelx_output == 1) & (binary_sobely_output == 1)&(binary_mag_thresh_output == 1)|(binary_r_output == 1)&(binary_g_output == 1)&(binary_b_output == 1)' thresholds to generate a binary image, and make the function 'pipeline_new'.\n",
    "\n",
    "![alt text][image3]\n",
    "\n",
    "### 2. Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "\n",
    "* 1.Set the source and destination points as following list.\n",
    "* 2.Draw the range line with the src points, as what I learned in project1.\n",
    "* 3.Use the function 'cv2.getPerspectiveTransform()', 'cv2.getPerspectiveTransform' and 'cv2.warpPerspective'to take out the birds-eye view\n",
    "\n",
    "This resulted in the following source and destination points:\n",
    "\n",
    "| Source        | Destination   | \n",
    "|:-------------:|:-------------:| \n",
    "| 180 , 700     | 160,  720     | \n",
    "| 570 , 460     | 160,   0      |\n",
    "| 740 , 460     | 1160,  0      |\n",
    "| 1160, 700     | 1160, 720     |\n",
    "\n",
    "Check if all of the lanes in the images have been surrounded in the range;\n",
    "\n",
    "![alt text][image4]\n",
    "![alt text][image5]\n",
    "![alt text][image6]\n",
    "![alt text][image7]\n",
    "![alt text][image8]\n",
    "![alt text][image9]\n",
    "\n",
    "\n",
    "I verified that the perspective transformation works as expected by drawing \"src\" and \"dst\" points and their warped counterparts on the test image to verify that the lines are parallel in the warped image.\n",
    "\n",
    "![alt text][image9]\n",
    "![alt text][image10]\n",
    "![alt text][image11]\n",
    "![alt text][image12]\n",
    "\n",
    "\n",
    "### 3. Detect lane pixels and fit to find the lane boundary. Determine the curvature of the lane and vehicle position with respect to center.\n",
    "\n",
    "* In the step first, I used the mothed as lession to pick up the midpoint of image' bottom and take the points for the left and right lines 'leftx_base' and 'rightx_base'.\n",
    "* Then wrote the sliding windows with the parameters of 'nwindows = 9', 'margin = 100' and 'minpix = 50'.\n",
    "* Take out the quadratic approximate curve with the function 'fit_polynomial()', and save the value of polynomial as 'left_fit' and 'right_fit'.\n",
    "* When I have the line, I used the previous polynomial to skip the sliding window with the function 'search_around_poly()', so I don't need to move sliding windows on every frame\n",
    "\n",
    "![alt text][image13]\n",
    "![alt text][image14]\n",
    "\n",
    "\n",
    "### 4. Determine the curvature of the lane and vehicle position with respect to center.\n",
    "\n",
    "* I used the function 'calc_curvature' what I learned in the lesson to calculate the curvature of the road. \n",
    "* I used the middle point of the image and the center position of the leftx and right to calculate the vehicle position with respect to center with the function 'calc_offset'\n",
    "\n",
    "\n",
    "### 5. Warp the detected lane boundaries back onto the original image.\n",
    "\n",
    "* Warp lane lines back onto original image using the function 'cv2.warpPerspective()'.\n",
    "* Combine lane lines with original image  using cv2.addWeighted.\n",
    "\n",
    "![alt text][image15]\n",
    "\n",
    "\n",
    "### 6. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "* I make a function 'annotate_video' to output the 'Left Curvature', 'Right Curvature' and 'Offset from center' on the video\n",
    "* For writing the data on the image I use the function of 'cv2.putText'\n",
    "\n",
    "![alt text][image16]\n",
    "\n",
    "---\n",
    "\n",
    "## Pipeline (video)\n",
    "\n",
    "### I condensed the operations into a single function 'video_pipline'  for the streamlined image pipeline that incorporates the video pipeline\n",
    "\n",
    "Here's a [link to my video result](./project_output_video.mp4)\n",
    "\n",
    "---\n",
    "\n",
    "## Discussion\n",
    "\n",
    "### 1. Briefly discuss any problems / issues you faced in your implementation of this project.  Where will your pipeline likely fail?  What could you do to make it more robust?\n",
    "\n",
    "Problem 1:\n",
    "I don't know that how to make the combination of color and gradient is the best.    \n",
    "\n",
    "Problem 2:\n",
    "The method of previous polynomial is good, but I think it will not work well when the car pass a large  curve, for example the harder challenge, is there any other good methods?\n",
    "\n",
    "Problem 3:\n",
    "I have tried the challenge video, but there is no white lane on the road as the following image, what should I do?\n",
    "![alt text][image17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
